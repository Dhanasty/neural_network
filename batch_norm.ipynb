{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain the concept of batch normalization in the context of Artificial Neural Networks\\n\\nBatch normalizatino is the process of normalizing the batches which is sent to hidden layer\\nthis is done to reduce the covariance shift , and mkaes the mean = 0 and variance = 1,\\nthis increases the training speed\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Explain the concept of batch normalization in the context of Artificial Neural Networks\n",
    "\n",
    "Batch normalizatino is the process of normalizing the batches which is sent to hidden layer\n",
    "this is done to reduce the covariance shift , and mkaes the mean = 0 and variance = 1,\n",
    "this increases the training speed\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2. Describe the benefits of using batch normalization during training? \\nFaster Training: By normalizing the inputs to each layer, batch normalization allows higher learning rates, which leads to faster convergence.\\nImproved Stability: Reducing internal covariate shifts helps stabilize the learning process, preventing issues like exploding or vanishing gradients.\\nRegularization Effect: Since normalization depends on the batch, there is a slight regularization effect (similar to dropout), which can reduce the need for other regularization techniques.\\nReduced Sensitivity to Initialization: With batch normalization, networks become less sensitive to weight initialization, making it easier to start training deep networks.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2. Describe the benefits of using batch normalization during training? \n",
    "Faster Training: By normalizing the inputs to each layer, batch normalization allows higher learning rates, which leads to faster convergence.\n",
    "Improved Stability: Reducing internal covariate shifts helps stabilize the learning process, preventing issues like exploding or vanishing gradients.\n",
    "Regularization Effect: Since normalization depends on the batch, there is a slight regularization effect (similar to dropout), which can reduce the need for other regularization techniques.\n",
    "Reduced Sensitivity to Initialization: With batch normalization, networks become less sensitive to weight initialization, making it easier to start training deep networks.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDiscuss the working principle of batch normalization, including the normalization step and the learnable\\nparameters.\\n\\n1) Calculate Mean and Standard Deviation\\n2) Normalize the inputs\\nScale parameter (\\nùõæ\\nŒ≥): This allows the model to adjust the variance of the normalized inputs.\\nShift parameter (\\nùõΩ\\nŒ≤): This allows the model to adjust the mean of the normalized inputs.\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Discuss the working principle of batch normalization, including the normalization step and the learnable\n",
    "parameters.\n",
    "\n",
    "1) Calculate Mean and Standard Deviation\n",
    "2) Normalize the inputs\n",
    "Scale parameter (\n",
    "ùõæ\n",
    "Œ≥): This allows the model to adjust the variance of the normalized inputs.\n",
    "Shift parameter (\n",
    "ùõΩ\n",
    "Œ≤): This allows the model to adjust the mean of the normalized inputs.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Testing data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Check the shape of the data\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0],cmap='gray')\n",
    "plt.title(f\"Label : {y_train[1]}\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[4],cmap='gray')\n",
    "plt.title(f\"Label : {y_train[4]}\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to the range [0, 1]\n",
    "x_train_normalized = x_train / 255.\n",
    "x_test_normalized = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded label for first training example: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels to one-hot encoded vectors\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"One-hot encoded label for first training example:\", y_train_one_hot[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers = [\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28], name=\"input_layer\"),  # No space in the name\n",
    "    tf.keras.layers.Dense(300, activation='relu', name='hidden_layer_1'),\n",
    "    tf.keras.layers.Dense(100, activation='relu', name='hidden_layer_2'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name=\"output_layer\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf = tf.keras.models.Sequential(Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=input_layer, built=True>,\n",
       " <Dense name=hidden_layer_1, built=True>,\n",
       " <Dense name=hidden_layer_2, built=True>,\n",
       " <Dense name=output_layer, built=True>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.compile(\n",
    "    optimizer='adam',  # You can also use 'sgd', 'rmsprop', etc.\n",
    "    loss='categorical_crossentropy',  # For classification tasks (if using one-hot encoded labels)\n",
    "    metrics=['accuracy']  # To monitor accuracy during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'sequential_input layer_sequential_4_input layer_sequential_5_input layer_sequential_7_hidden_layer_1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Your normalized training data (e.g., MNIST)\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# One-hot encoded labels\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'sequential_input layer_sequential_4_input layer_sequential_5_input layer_sequential_7_hidden_layer_1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$"
     ]
    }
   ],
   "source": [
    "history = model_clf.fit(\n",
    "    x_train_normalized,  # Your normalized training data (e.g., MNIST)\n",
    "    y_train_one_hot,  # One-hot encoded labels\n",
    "    batch_size=32,  # Batch size\n",
    "    epochs=10,  # Number of epochs\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_normalized.shape)  # Should be (num_samples, 28, 28)\n",
    "print(y_train_one_hot.shape)     # Should be (num_samples, 10) if one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'sequential_input layer_sequential_4_input layer_sequential_5_input layer_sequential_11_hidden1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m model_clf\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Adam optimizer\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Loss for multi-class classification\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Metric to monitor\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Your normalized training data (e.g., MNIST)\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# One-hot encoded labels\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'sequential_input layer_sequential_4_input layer_sequential_5_input layer_sequential_11_hidden1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$"
     ]
    }
   ],
   "source": [
    "Layers = [\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28], name=\"input\"),  # Valid name, no spaces\n",
    "    tf.keras.layers.Dense(300, activation='relu', name=\"hidden1\"),  # No invalid characters\n",
    "    tf.keras.layers.Dense(100, activation='relu', name=\"hidden2\"),  # No invalid characters\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name=\"output\")  # No invalid characters\n",
    "]\n",
    "\n",
    "# Create the model\n",
    "model_clf = tf.keras.models.Sequential(Layers)\n",
    "\n",
    "# Compile the model\n",
    "model_clf.compile(\n",
    "    optimizer='adam',  # Adam optimizer\n",
    "    loss='categorical_crossentropy',  # Loss for multi-class classification\n",
    "    metrics=['accuracy']  # Metric to monitor\n",
    ")\n",
    "\n",
    "history = model_clf.fit(\n",
    "    x_train_normalized,  # Your normalized training data (e.g., MNIST)\n",
    "    y_train_one_hot,  # One-hot encoded labels\n",
    "    batch_size=32,  # Batch size\n",
    "    epochs=10,  # Number of epochs\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type of X_train_full: uint8,\n",
      " shape of X_train_full: (60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ inputLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ hiddenLayer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ hiddenLayer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ outputLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ inputLayer (\u001b[38;5;33mFlatten\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ hiddenLayer1 (\u001b[38;5;33mDense\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            ‚îÇ       \u001b[38;5;34m235,500\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ hiddenLayer2 (\u001b[38;5;33mDense\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            ‚îÇ        \u001b[38;5;34m30,100\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ outputLayer (\u001b[38;5;33mDense\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,010\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
    "print(f\"data type of X_train_full: {X_train_full.dtype},\\n shape of X_train_full: {X_train_full.shape}\")\n",
    "X_test.shape\n",
    "len(X_test[1][0])\n",
    "\n",
    "# create a validation data set from the full training data\n",
    "\n",
    "# Scale the data between 0 to 1 by dividing it by 255. as its an unsigned data between 0-255 range\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# scale the test set as well\n",
    "\n",
    "X_test = X_test / 255.\n",
    "\n",
    "len(X_train_full[5000:] )\n",
    "\n",
    "# Lets view some data\n",
    "\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,15))\n",
    "# sns.heatmap(X_train[0], annot=True, cmap=\"binary\")\n",
    "\n",
    "# Architecture Used:\n",
    "\n",
    "\n",
    "\n",
    "# Creating layers of ANN\n",
    "\n",
    "LAYERS = [tf.keras.layers.Flatten(input_shape=[28, 28], name=\"inputLayer\"),\n",
    "tf.keras.layers.Dense(300, activation=\"relu\", name=\"hiddenLayer1\"),\n",
    "tf.keras.layers.Dense(100, activation=\"relu\", name=\"hiddenLayer2\"),\n",
    "tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputLayer\")]\n",
    "\n",
    "model_clf = tf.keras.models.Sequential(LAYERS)\n",
    "model_clf.layers\n",
    "model_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'sequential_input layer_sequential_4_input layer_sequential_5_input layer_sequential_14_hiddenLayer1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_clf\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Adam optimizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Loss for multi-class classification\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Metric to monitor\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Your normalized training data (e.g., MNIST)\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# One-hot encoded labels\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'sequential_input layer_sequential_4_input layer_sequential_5_input layer_sequential_14_hiddenLayer1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_clf.compile(\n",
    "    optimizer='adam',  # Adam optimizer\n",
    "    loss='categorical_crossentropy',  # Loss for multi-class classification\n",
    "    metrics=['accuracy']  # Metric to monitor\n",
    ")\n",
    "\n",
    "history = model_clf.fit(\n",
    "    X_train,  # Your normalized training data (e.g., MNIST)\n",
    "    y_train_one_hot,  # One-hot encoded labels\n",
    "    batch_size=32,  # Batch size\n",
    "    epochs=10,  # Number of epochs\n",
    "    validation_data=(X_t)\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'sequential_input layer_sequential_4_input layer_sequential_5_input layer_sequential_15_hidden_layer_1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 32\u001b[0m\n\u001b[0;32m     25\u001b[0m model_clf\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     26\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Using categorical crossentropy for one-hot labels\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Training data\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# One-hot encoded labels\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_one_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     41\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model_clf\u001b[38;5;241m.\u001b[39mevaluate(x_test_normalized, y_test_one_hot)\n",
      "File \u001b[1;32mc:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'sequential_input layer_sequential_4_input layer_sequential_5_input layer_sequential_15_hidden_layer_1_kernel_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Load and Preprocess the MNIST Dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train_normalized = x_train.astype('float32') / 255.0\n",
    "x_test_normalized = x_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Step 2: Define a Simple Feedforward Neural Network\n",
    "model_clf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='hidden_layer_1'),\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='hidden_layer_2'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model_clf.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Using categorical crossentropy for one-hot labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model_clf.fit(\n",
    "    x_train_normalized,  # Training data\n",
    "    y_train_one_hot,  # One-hot encoded labels\n",
    "    validation_data=(x_test_normalized, y_test_one_hot),  # Validation data\n",
    "    batch_size=32,  # Batch size\n",
    "    epochs=10  # Number of epochs\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_clf.evaluate(x_test_normalized, y_test_one_hot)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Dhana\\miniconda3\\envs\\git_pw\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.4257 - val_accuracy: 0.9625 - val_loss: 0.1226\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1068 - val_accuracy: 0.9723 - val_loss: 0.0900\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.0705 - val_accuracy: 0.9764 - val_loss: 0.0786\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0485 - val_accuracy: 0.9748 - val_loss: 0.0821\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0419 - val_accuracy: 0.9727 - val_loss: 0.0917\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0326 - val_accuracy: 0.9754 - val_loss: 0.0823\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0251 - val_accuracy: 0.9801 - val_loss: 0.0758\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0235 - val_accuracy: 0.9802 - val_loss: 0.0738\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0180 - val_accuracy: 0.9802 - val_loss: 0.0841\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0173 - val_accuracy: 0.9778 - val_loss: 0.0903\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9754 - loss: 0.1028\n",
      "Test accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train_normalized = x_train.astype('float32') / 255.0\n",
    "x_test_normalized = x_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Clear the current Keras session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Define a Simple Feedforward Neural Network with valid names\n",
    "model_clf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name=\"input_yer\"),  # No spaces\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='hidden_yer_1'),  # Use underscores\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='hiddenayer_2'),  # Use underscores\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name=\"outpu_layer\")  # No spaces\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_clf.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model_clf.fit(\n",
    "    x_train_normalized,  # Training data\n",
    "    y_train_one_hot,  # One-hot encoded labels\n",
    "    validation_data=(x_test_normalized, y_test_one_hot),  # Validation data\n",
    "    batch_size=32,  # Batch size\n",
    "    epochs=10  # Number of epochs\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_clf.evaluate(x_test_normalized, y_test_one_hot)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.4133 - val_accuracy: 0.9543 - val_loss: 0.1429\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1221 - val_accuracy: 0.9624 - val_loss: 0.1192\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.0967 - val_accuracy: 0.9736 - val_loss: 0.0896\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0768 - val_accuracy: 0.9705 - val_loss: 0.1056\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0640 - val_accuracy: 0.9742 - val_loss: 0.0823\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0573 - val_accuracy: 0.9766 - val_loss: 0.0758\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0501 - val_accuracy: 0.9742 - val_loss: 0.0838\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0452 - val_accuracy: 0.9792 - val_loss: 0.0722\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0402 - val_accuracy: 0.9784 - val_loss: 0.0758\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0392 - val_accuracy: 0.9752 - val_loss: 0.0824\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0967\n",
      "Test accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Load and Preprocess the MNIST Dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train_normalized = x_train.astype('float32') / 255.0\n",
    "x_test_normalized = x_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Clear the current Keras session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Step 2: Define a Simple Feedforward Neural Network with Batch Normalization\n",
    "model_clf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name=\"inp_layer\"),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='hien_layer_1'),\n",
    "    tf.keras.layers.BatchNormalization(),  # Batch Normalization\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='hden_layer_2'),\n",
    "    tf.keras.layers.BatchNormalization(),  # Batch Normalization\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name=\"out_layer\")\n",
    "])\n",
    "\n",
    "# Step 3: Compile the Model\n",
    "model_clf.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Step 4: Train the Model\n",
    "history = model_clf.fit(\n",
    "    x_train_normalized,  # Training data\n",
    "    y_train_one_hot,  # One-hot encoded labels\n",
    "    validation_data=(x_test_normalized, y_test_one_hot),  # Validation data\n",
    "    batch_size=32,  # Batch size\n",
    "    epochs=10  # Number of epochs\n",
    ")\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "test_loss, test_accuracy = model_clf.evaluate(x_test_normalized, y_test_one_hot)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "git_pw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
